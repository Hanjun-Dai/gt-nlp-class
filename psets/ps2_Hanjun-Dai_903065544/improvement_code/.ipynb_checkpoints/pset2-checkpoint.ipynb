{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['mat']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import gtnlplib.preproc\n",
    "import gtnlplib.preproc_metrics\n",
    "\n",
    "import gtnlplib.clf_base\n",
    "import gtnlplib.wordlist\n",
    "import gtnlplib.naivebayes\n",
    "import gtnlplib.perceptron\n",
    "import gtnlplib.avg_perceptron\n",
    "import gtnlplib.logreg\n",
    "\n",
    "import gtnlplib.scorer\n",
    "import gtnlplib.constants\n",
    "import gtnlplib.analysis\n",
    "import gtnlplib.weight_ensemble\n",
    "# this enables you to create inline plots in the notebook \n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TRAINKEY, DEVKEY and TESTKEY are defined in the gtnlplib.constants module\n",
    "\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.TRAINKEY)\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.DEVKEY)\n",
    "## uncomment once you have the test data\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.TESTKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word types 18430\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.preproc)\n",
    "ac_train = gtnlplib.preproc.getAllCounts(gtnlplib.preproc.dataIterator(gtnlplib.constants.TRAINKEY))\n",
    "ac_dev = gtnlplib.preproc.getAllCounts(gtnlplib.preproc.dataIterator(gtnlplib.constants.DEVKEY))\n",
    "print \"number of word types\",len(ac_train.keys())-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Word list classification #\n",
    "(_setting weights - 2 pts, Deliverable 3 - 1 pt. Total 3 pts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poswords, negwords = gtnlplib.wordlist.loadSentimentWords (gtnlplib.constants.SENTIMENT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 classes in key: set(['NEG', 'NEU', 'POS'])\n",
      "3 classes in response: set(['NEG', 'NEU', 'POS'])\n",
      "confusion matrix\n",
      "key\\response:\tNEG\tNEU\tPOS\n",
      "NEG\t\t36\t14\t61\t\n",
      "NEU\t\t22\t14\t99\t\n",
      "POS\t\t9\t13\t126\t\n",
      "----------------\n",
      "accuracy: 0.4467 = 176/394\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.wordlist)\n",
    "weights_wlc = gtnlplib.wordlist.learnWLCWeights (poswords, negwords)\n",
    "outfile = 'word_list.txt'\n",
    "mat = gtnlplib.clf_base.evalClassifier(weights_wlc,outfile, gtnlplib.constants.DEVKEY)\n",
    "print gtnlplib.scorer.printScoreMessage(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Naive Bayes #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts, class_counts,allkeys = gtnlplib.preproc.getCountsAndKeys(gtnlplib.constants.TRAINKEY)\n",
    "reload(gtnlplib.naivebayes)\n",
    "weights_nb = gtnlplib.naivebayes.learnNBWeights (counts, class_counts, allkeys, alpha=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 classes in key: set(['NEG', 'NEU', 'POS'])\n",
      "3 classes in response: set(['NEG', 'NEU', 'POS'])\n",
      "confusion matrix\n",
      "key\\response:\tNEG\tNEU\tPOS\n",
      "NEG\t\t15\t85\t11\t\n",
      "NEU\t\t12\t97\t26\t\n",
      "POS\t\t8\t46\t94\t\n",
      "----------------\n",
      "accuracy: 0.5228 = 206/394\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "outfile = 'nb.txt'\n",
    "mat = gtnlplib.clf_base.evalClassifier(weights_nb,outfile, gtnlplib.constants.DEVKEY)\n",
    "print gtnlplib.scorer.printScoreMessage(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 1.3, 1.5, 1.8, 2, 5, 10] #your choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_nb_alphas, tr_accs, dv_accs = gtnlplib.naivebayes.regularization_using_grid_search (alphas,counts, class_counts, allkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.987820512821 0.467005076142\n",
      "0.001 0.986538461538 0.472081218274\n",
      "0.01 0.985897435897 0.507614213198\n",
      "0.1 0.982692307692 0.517766497462\n",
      "0.5 0.962179487179 0.515228426396\n",
      "1 0.94358974359 0.522842639594\n",
      "1.3 0.93141025641 0.522842639594\n",
      "1.5 0.924358974359 0.522842639594\n",
      "1.8 0.904487179487 0.522842639594\n",
      "2 0.896153846154 0.520304568528\n",
      "5 0.712820512821 0.464467005076\n",
      "10 0.605128205128 0.444162436548\n"
     ]
    }
   ],
   "source": [
    "for i,alpha in enumerate (alphas):\n",
    "    print alpha, tr_accs[i], dv_accs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Perceptron #\n",
    "(_ 6 points total _)\n",
    "\n",
    "Implement a perceptron classifier. Using the feature-function\n",
    "representation, include features for each word-class pair, and also an\n",
    "** offset ** feature for each class. Given a set of word counts $\\vec{x}_i$,\n",
    "a true label $y_i$, and a guessed label $\\hat{y}$, your update will be\n",
    "\\begin{align*}\n",
    "\\hat{y} & \\leftarrow \\text{argmax}_y \\vec{\\theta}' f(\\vec{x}_i,y)\\\\\n",
    "\\vec{\\theta} & \\leftarrow \\vec{\\theta} + f(\\vec{x}_i, y_i) - f(\\vec{x}_i, \\hat{y}).\n",
    "\\end{align*}\n",
    "\n",
    "Please write this yourself -- do not use any libraries, and try not to look\n",
    "at other code online.\n",
    "\n",
    "**Sanity check** If you are not careful, learning can be slow. \n",
    "You may need to think a little about how to do this update efficiently. \n",
    "\n",
    "- On my laptop, I can make 10 passes on the training data in roughly 30 seconds, including evaluating the accuracy on the dev and training sets. \n",
    "- You can use the ```%%timeit``` cell magic to compute statistics like this.\n",
    "- Your code doesn't have to be as fast as mine, but it needs to be written intelligently, and it needs to be fast enough for you to debug it properly.\n",
    "- The ```%%prun``` cell magic is also useful for diagnosing speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tr_insts,all_dev_insts= gtnlplib.preproc.loadInstances(gtnlplib.constants.TRAINKEY, gtnlplib.constants.DEVKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev:  0.428934010152 train:  0.400641025641\n",
      "1 dev:  0.418781725888 train:  0.533974358974\n",
      "2 dev:  0.5 train:  0.616666666667\n",
      "3 dev:  0.403553299492 train:  0.662179487179\n",
      "4 dev:  0.505076142132 train:  0.657692307692\n",
      "5 dev:  0.560913705584 train:  0.755128205128\n",
      "6 dev:  0.527918781726 train:  0.798076923077\n",
      "7 dev:  0.477157360406 train:  0.839102564103\n",
      "8 dev:  0.46192893401 train:  0.790384615385\n",
      "9 dev:  0.52538071066 train:  0.836538461538\n",
      "10 dev:  0.535532994924 train:  0.882692307692\n",
      "11 dev:  0.530456852792 train:  0.898717948718\n",
      "12 dev:  0.52538071066 train:  0.917307692308\n",
      "13 dev:  0.555837563452 train:  0.90641025641\n",
      "14 dev:  0.545685279188 train:  0.933333333333\n",
      "15 dev:  0.520304568528 train:  0.955769230769\n",
      "16 dev:  0.540609137056 train:  0.967948717949\n",
      "17 dev:  0.560913705584 train:  0.967307692308\n",
      "18 dev:  0.530456852792 train:  0.958974358974\n",
      "19 dev:  0.482233502538 train:  0.95641025641\n",
      "20 dev:  0.472081218274 train:  0.971794871795\n",
      "21 dev:  0.530456852792 train:  0.971794871795\n",
      "22 dev:  0.53807106599 train:  0.98141025641\n",
      "23 dev:  0.53807106599 train:  0.970512820513\n",
      "24 dev:  0.530456852792 train:  0.980769230769\n",
      "25 dev:  0.56345177665 train:  0.95\n",
      "26 dev:  0.565989847716 train:  0.944871794872\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.perceptron)\n",
    "outfile = \"perc.txt\"\n",
    "w_perc,tr_acc_perc,dv_acc_perc = gtnlplib.perceptron.trainPerceptron(27, all_tr_insts,gtnlplib.constants.ALL_LABELS, outfile, gtnlplib.constants.DEVKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Averaged Perceptron #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev:  0.484771573604 train:  0.400641025641\n",
      "1 dev:  0.517766497462 train:  0.533974358974\n",
      "2 dev:  0.530456852792 train:  0.616666666667\n",
      "3 dev:  0.55076142132 train:  0.662179487179\n",
      "4 dev:  0.532994923858 train:  0.657692307692\n",
      "5 dev:  0.555837563452 train:  0.755128205128\n",
      "6 dev:  0.568527918782 train:  0.798076923077\n",
      "7 dev:  0.578680203046 train:  0.839102564103\n",
      "8 dev:  0.573604060914 train:  0.790384615385\n",
      "9 dev:  0.573604060914 train:  0.836538461538\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.avg_perceptron)\n",
    "# again, this takes roughly 30 seconds for me\n",
    "outfile = \"ap.txt\"\n",
    "w_ap,tr_acc_ap,dv_acc_ap = gtnlplib.avg_perceptron.trainAvgPerceptron(10,all_tr_insts,gtnlplib.constants.ALL_LABELS, outfile,gtnlplib.constants.DEVKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Logistic regression #\n",
    "\n",
    "Now you will complete an implementation of logistic regression.\n",
    "We've provided a lot of scaffolding code, you just need to fill in some key parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev: 0.451776649746 train: 0.407953816549\n",
      "1 dev: 0.477157360406 train: 0.4791533034\n",
      "2 dev: 0.479695431472 train: 0.514432328416\n",
      "3 dev: 0.489847715736 train: 0.529185375241\n",
      "4 dev: 0.507614213198 train: 0.556125721616\n",
      "5 dev: 0.51269035533 train: 0.573444515715\n",
      "6 dev: 0.52538071066 train: 0.590763309814\n",
      "7 dev: 0.532994923858 train: 0.599743425273\n",
      "8 dev: 0.540609137056 train: 0.607440667094\n",
      "9 dev: 0.545685279188 train: 0.614496472097\n",
      "10 dev: 0.545685279188 train: 0.620269403464\n",
      "11 dev: 0.548223350254 train: 0.628608082104\n",
      "12 dev: 0.553299492386 train: 0.631173829378\n",
      "13 dev: 0.553299492386 train: 0.636946760744\n",
      "14 dev: 0.558375634518 train: 0.645926876203\n",
      "15 dev: 0.56345177665 train: 0.653624118024\n",
      "16 dev: 0.56345177665 train: 0.661321359846\n",
      "17 dev: 0.558375634518 train: 0.667735728031\n",
      "18 dev: 0.558375634518 train: 0.67222578576\n",
      "19 dev: 0.560913705584 train: 0.677998717126\n",
      "20 dev: 0.56345177665 train: 0.683130211674\n",
      "21 dev: 0.56345177665 train: 0.688261706222\n",
      "22 dev: 0.560913705584 train: 0.69339320077\n",
      "23 dev: 0.558375634518 train: 0.697883258499\n",
      "24 dev: 0.558375634518 train: 0.70173187941\n",
      "25 dev: 0.56345177665 train: 0.704297626684\n",
      "26 dev: 0.565989847716 train: 0.705580500321\n",
      "27 dev: 0.565989847716 train: 0.709429121232\n",
      "28 dev: 0.560913705584 train: 0.711994868505\n",
      "29 dev: 0.560913705584 train: 0.712636305324\n",
      "30 dev: 0.560913705584 train: 0.715843489416\n",
      "31 dev: 0.555837563452 train: 0.720974983964\n",
      "32 dev: 0.555837563452 train: 0.724182168056\n",
      "33 dev: 0.555837563452 train: 0.725465041693\n",
      "34 dev: 0.558375634518 train: 0.728030788967\n",
      "35 dev: 0.558375634518 train: 0.729955099423\n",
      "36 dev: 0.558375634518 train: 0.735728030789\n",
      "37 dev: 0.558375634518 train: 0.738293778063\n",
      "38 dev: 0.558375634518 train: 0.740859525337\n",
      "39 dev: 0.558375634518 train: 0.742783835792\n",
      "40 dev: 0.558375634518 train: 0.744708146248\n",
      "41 dev: 0.56345177665 train: 0.746632456703\n",
      "42 dev: 0.565989847716 train: 0.751122514432\n",
      "43 dev: 0.568527918782 train: 0.757536882617\n",
      "44 dev: 0.568527918782 train: 0.758819756254\n",
      "45 dev: 0.571065989848 train: 0.762026940346\n",
      "46 dev: 0.571065989848 train: 0.762668377165\n",
      "47 dev: 0.571065989848 train: 0.763309813983\n",
      "48 dev: 0.573604060914 train: 0.765234124439\n",
      "49 dev: 0.571065989848 train: 0.767799871713\n",
      "50 dev: 0.571065989848 train: 0.770365618987\n",
      "51 dev: 0.571065989848 train: 0.77293136626\n",
      "52 dev: 0.568527918782 train: 0.774855676716\n",
      "53 dev: 0.568527918782 train: 0.778062860808\n",
      "54 dev: 0.568527918782 train: 0.779345734445\n",
      "55 dev: 0.568527918782 train: 0.781270044901\n",
      "56 dev: 0.568527918782 train: 0.781911481719\n",
      "57 dev: 0.571065989848 train: 0.783194355356\n",
      "58 dev: 0.573604060914 train: 0.784477228993\n",
      "59 dev: 0.573604060914 train: 0.785118665811\n",
      "60 dev: 0.573604060914 train: 0.78576010263\n",
      "61 dev: 0.573604060914 train: 0.787042976267\n",
      "62 dev: 0.573604060914 train: 0.788967286722\n",
      "63 dev: 0.573604060914 train: 0.790250160359\n",
      "64 dev: 0.573604060914 train: 0.790250160359\n",
      "65 dev: 0.57614213198 train: 0.792174470815\n",
      "66 dev: 0.57614213198 train: 0.793457344452\n",
      "67 dev: 0.57614213198 train: 0.793457344452\n",
      "68 dev: 0.573604060914 train: 0.794740218089\n",
      "69 dev: 0.57614213198 train: 0.795381654907\n",
      "70 dev: 0.57614213198 train: 0.795381654907\n",
      "71 dev: 0.57614213198 train: 0.796023091725\n",
      "72 dev: 0.57614213198 train: 0.796664528544\n",
      "73 dev: 0.571065989848 train: 0.797305965362\n",
      "74 dev: 0.573604060914 train: 0.799230275818\n",
      "75 dev: 0.57614213198 train: 0.801796023092\n",
      "76 dev: 0.583756345178 train: 0.80243745991\n",
      "77 dev: 0.583756345178 train: 0.803720333547\n",
      "78 dev: 0.583756345178 train: 0.804361770366\n",
      "79 dev: 0.581218274112 train: 0.805644644003\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.logreg)\n",
    "outfile = \"sgd.txt\"\n",
    "w_sgd,tr_acc_sgd,dv_acc_sgd = gtnlplib.logreg.trainLRbySGD(80,all_tr_insts, outfile, gtnlplib.constants.DEVKEY, regularizer=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Bakeoff! #\n",
    "\n",
    "48 hours before the assignment is due, I will send you unlabeled test\n",
    "data. Your job is to produce a response file, and submit it to our Kaggle\n",
    "bakeoff ([link here](https://inclass.kaggle.com/c/gt-book-review-sentiment-analysis)).\n",
    "The Kaggle contest compares your classifier's results on the dev data to generate a\n",
    "class-visible leaderboard, and compares your classifier's results on the unlabeled\n",
    "test data for the bakeoff. You can use the dev data results as a sanity\n",
    "check, to make sure you submit the correct file.\n",
    "\n",
    "I'll present the results in class and give the best scorers a chance to explain\n",
    "what they did.\n",
    "\n",
    "** Deliverable 10 ** (3 points) Run your best system from any part of the\n",
    "assignment on the test data using the `generateKaggleSubmission()` function. Submit\n",
    "your response file to the class [Kaggle bakeoff](https://inclass.kaggle.com/c/gt-book-review-sentiment-analysis). Also submit your Kaggle response file to T-Square as 'lastname-firstname.response'. The top\n",
    "scores will be announced in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593908629442 0.2 0.2 0.1 1.0\n",
      "0.596446700508 0.3 0.2 0.1 1.0\n",
      "0.598984771574 0.4 0.2 0.1 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-6d5ccad20031>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mw2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mw1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 \u001b[0mavg_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgtnlplib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_ensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_wlc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mweights_nb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw_ap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw_sgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m                 \u001b[0myourBestWeights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_weight\u001b[0m \u001b[1;31m# Change this to your best model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgtnlplib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerateKaggleSubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myourBestWeights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dai-Hanjun.response'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hanjun/Workspace/Courses/gt-nlp-class/psets/better-ps2/gtnlplib/weight_ensemble.pyc\u001b[0m in \u001b[0;36mensemble\u001b[1;34m(weighted_classifiers)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweighted_classifiers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                         \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.weight_ensemble)\n",
    "reload(gtnlplib.clf_base)\n",
    "best_acc = 0.0\n",
    "for w4 in np.arange(1, 5, 0.1):\n",
    "    for w3 in np.arange(0.1, 2, 0.1):\n",
    "        for w2 in np.arange(0.1, 10, 0.1):\n",
    "            for w1 in np.arange(0.1, 10, 0.1):\n",
    "                avg_weight = gtnlplib.weight_ensemble.ensemble([(weights_wlc, w1), (weights_nb, w2), (w_ap, w3), (w_sgd, w4)])\n",
    "                yourBestWeights = avg_weight # Change this to your best model\n",
    "                acc = gtnlplib.clf_base.generateKaggleSubmission(yourBestWeights, 'Dai-Hanjun.response')\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_w1 = w1\n",
    "                    best_w2 = w2\n",
    "                    best_w3 = w3\n",
    "                    best_w4 = w4\n",
    "                    print best_acc, w1, w2, w3, w4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
