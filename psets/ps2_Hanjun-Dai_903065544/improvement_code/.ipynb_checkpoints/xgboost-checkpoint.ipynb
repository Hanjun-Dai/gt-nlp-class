{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import xgboost as xgb\n",
    "import gtnlplib.preproc\n",
    "import gtnlplib.constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.TRAINKEY)\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.DEVKEY)\n",
    "all_tr_insts,all_dev_insts= gtnlplib.preproc.loadInstances(gtnlplib.constants.TRAINKEY, gtnlplib.constants.DEVKEY)\n",
    "ac_train = gtnlplib.preproc.getAllCounts(gtnlplib.preproc.dataIterator(gtnlplib.constants.TRAINKEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_idx = {}\n",
    "for w in ac_train:\n",
    "    word_idx[w] = len(word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_XY(all_instances):\n",
    "    idx_dict = {'POS' : 0, 'NEG' : 1, 'NEU' : 2}\n",
    "    X = np.zeros((len(all_instances), len(word_idx)))\n",
    "    Y = []\n",
    "    for sample_idx in range(len(all_instances)):\n",
    "        sample = all_instances[sample_idx]\n",
    "        feat = sample[0]\n",
    "        label = sample[1]\n",
    "        Y.append(idx_dict[label])\n",
    "        for w in feat:\n",
    "            if w in word_idx:\n",
    "                X[sample_idx][word_idx[w]] = 1\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "train_X, train_Y = get_XY(all_tr_insts)\n",
    "dev_X, dev_Y = get_XY(all_dev_insts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xg_train = xgb.DMatrix( train_X, label=train_Y)\n",
    "xg_dev = xgb.DMatrix(dev_X, label=dev_Y)\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.01\n",
    "param['max_depth'] = 2\n",
    "param['lambda'] = 5\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 3\n",
    "\n",
    "watchlist = [ (xg_train,'train'), (xg_dev, 'dev') ]\n",
    "num_round = 10000\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist );\n",
    "# get prediction\n",
    "pred = bst.predict( xg_dev );\n",
    "\n",
    "print ('predicting, classification error=%f' % (sum( int(pred[i]) != dev_Y[i] for i in range(len(dev_Y))) / float(len(dev_Y)) ))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
