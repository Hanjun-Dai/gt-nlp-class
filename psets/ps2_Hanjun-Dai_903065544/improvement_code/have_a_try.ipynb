{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import gtnlplib.preproc\n",
    "import gtnlplib.preproc_metrics\n",
    "\n",
    "import gtnlplib.clf_base\n",
    "import gtnlplib.wordlist\n",
    "import gtnlplib.naivebayes\n",
    "import gtnlplib.perceptron\n",
    "import gtnlplib.avg_perceptron\n",
    "import gtnlplib.logreg\n",
    "\n",
    "import gtnlplib.scorer\n",
    "import gtnlplib.constants\n",
    "import gtnlplib.analysis\n",
    "import gtnlplib.weight_ensemble\n",
    "# this enables you to create inline plots in the notebook \n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(gtnlplib.preproc)\n",
    "train_key = 'data/train_randconcat.key'\n",
    "gtnlplib.preproc.docsToBOWs(train_key)\n",
    "#gtnlplib.preproc.docsToBOWs(gtnlplib.constants.DEVKEY)\n",
    "all_tr_insts,all_dev_insts= gtnlplib.preproc.loadInstances(train_key, gtnlplib.constants.DEVKEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(gtnlplib.logreg)\n",
    "outfile = \"sgd.txt\"\n",
    "w_sgd,tr_acc_sgd,dv_acc_sgd = gtnlplib.logreg.trainLRbySGD(1000,all_tr_insts, outfile, gtnlplib.constants.DEVKEY, regularizer=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 classes in key: set(['NEG', 'NEU', 'POS'])\n",
      "3 classes in response: set(['NEG', 'NEU', 'POS'])\n",
      "confusion matrix\n",
      "key\\response:\tNEG\tNEU\tPOS\n",
      "NEG\t\t36\t14\t61\t\n",
      "NEU\t\t22\t14\t99\t\n",
      "POS\t\t9\t13\t126\t\n",
      "----------------\n",
      "accuracy: 0.4467 = 176/394\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.wordlist)\n",
    "\n",
    "poswords, negwords = gtnlplib.wordlist.loadSentimentWords (gtnlplib.constants.SENTIMENT_FILE)\n",
    "weights_wlc = gtnlplib.wordlist.learnWLCWeights (poswords, negwords)\n",
    "outfile = 'word_list.txt'\n",
    "mat = gtnlplib.clf_base.evalClassifier(weights_wlc,outfile, gtnlplib.constants.DEVKEY)\n",
    "print gtnlplib.scorer.printScoreMessage(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'data/train.bow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-29f9baaa072a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#weights_nb = gtnlplib.naivebayes.learnNBWeights (counts, class_counts, allkeys, alpha=1.3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0malphas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#your choice!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mweights_nb_alphas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_accs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdv_accs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgtnlplib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaivebayes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularization_using_grid_search\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_accs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdv_accs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hanjun/Workspace/Courses/gt-nlp-class/psets/better-ps2/gtnlplib/naivebayes.pyc\u001b[0m in \u001b[0;36mregularization_using_grid_search\u001b[1;34m(alphas, counts, class_counts, allkeys, tr_outfile, dv_outfile)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mweights_nb_alphas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearnNBWeights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mconfusion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevalClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_nb_alphas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr_outfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTRAINKEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mtr_accs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mconfusion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevalClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_nb_alphas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdv_outfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDEVKEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hanjun/Workspace/Courses/gt-nlp-class/psets/better-ps2/gtnlplib/clf_base.pyc\u001b[0m in \u001b[0;36mevalClassifier\u001b[1;34m(weights, outfilename, testfile, test_mode)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevalClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutfilename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#iterate through eval set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[1;33m>>\u001b[0m\u001b[0moutfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mALL_LABELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#print prediction to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtest_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hanjun/Workspace/Courses/gt-nlp-class/psets/better-ps2/gtnlplib/preproc.pyc\u001b[0m in \u001b[0;36mdataIterator\u001b[1;34m(keyfile, test_mode)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mfaster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \"\"\"\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'key'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bow'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkeyline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'data/train.bow'"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.naivebayes)\n",
    "counts, class_counts,allkeys = gtnlplib.preproc.getCountsAndKeys(train_key)\n",
    "#weights_nb = gtnlplib.naivebayes.learnNBWeights (counts, class_counts, allkeys, alpha=1.3)\n",
    "alphas = [0.5, 1, 1.3, 1.5, 1.8, 2] #your choice!\n",
    "weights_nb_alphas, tr_accs, dv_accs = gtnlplib.naivebayes.regularization_using_grid_search (alphas,counts, class_counts, allkeys)\n",
    "for i,alpha in enumerate (alphas):\n",
    "    print alpha, tr_accs[i], dv_accs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
