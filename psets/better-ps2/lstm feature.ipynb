{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import xgboost as xgb\n",
    "import gtnlplib.preproc\n",
    "import gtnlplib.constants\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import cPickle as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(gtnlplib.preproc)\n",
    "\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.TRAINKEY)\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.DEVKEY)\n",
    "all_tr_insts,all_dev_insts= gtnlplib.preproc.loadInstances(gtnlplib.constants.TRAINKEY, gtnlplib.constants.DEVKEY)\n",
    "ac_train = gtnlplib.preproc.getAllCounts(gtnlplib.preproc.dataIterator(gtnlplib.constants.TRAINKEY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ac_train[gtnlplib.constants.OFFSET] = 0\n",
    "a = sorted(ac_train.items(), key=lambda x:x[1], reverse=True)\n",
    "word_idx = {}\n",
    "for i in range(len(a)):\n",
    "    word_idx[a[i][0]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_XY(filekey):\n",
    "    idx_dict = {'POS' : 0, 'NEG' : 1, 'NEU' : 2}\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(filekey, 'r') as f_idxes:\n",
    "        root_folder = filekey.split('/')[0]\n",
    "        for name_label in f_idxes:\n",
    "            filename, label = name_label.split(' ')\n",
    "            filename = root_folder + '/' + filename\n",
    "            label = label.strip()\n",
    "            with open(filename.strip(), 'r') as f:                \n",
    "                cur_seq = []\n",
    "                Y.append(idx_dict[label])\n",
    "                for line in f:\n",
    "                    decoded = line.decode('ascii','ignore')\n",
    "                    sentences = sent_tokenize(decoded)           \n",
    "                    for s in sentences:\n",
    "                        words = word_tokenize(s)        \n",
    "                        for w in words:\n",
    "                            w = w.lower()\n",
    "                            if w in word_idx:\n",
    "                                cur_seq.append(word_idx[w])\n",
    "                X.append(cur_seq)\n",
    "    return X, Y\n",
    "\n",
    "trainX, trainY = get_XY(gtnlplib.constants.TRAINKEY)\n",
    "devX, devY = get_XY(gtnlplib.constants.DEVKEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_file = open('lstm/amazon.pkl', 'wb')\n",
    "out_dict = {'train' : (trainX, trainY), 'dev' : (devX, devY)}\n",
    "cp.dump(out_dict, out_file, cp.HIGHEST_PROTOCOL)\n",
    "out_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
