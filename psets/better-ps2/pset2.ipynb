{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['mat']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import gtnlplib.preproc\n",
    "import gtnlplib.preproc_metrics\n",
    "\n",
    "import gtnlplib.clf_base\n",
    "import gtnlplib.wordlist\n",
    "import gtnlplib.naivebayes\n",
    "import gtnlplib.perceptron\n",
    "import gtnlplib.avg_perceptron\n",
    "import gtnlplib.logreg\n",
    "\n",
    "import gtnlplib.scorer\n",
    "import gtnlplib.constants\n",
    "import gtnlplib.analysis\n",
    "import gtnlplib.weight_ensemble\n",
    "# this enables you to create inline plots in the notebook \n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TRAINKEY, DEVKEY and TESTKEY are defined in the gtnlplib.constants module\n",
    "reload(gtnlplib.preproc)\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.TRAINKEY)\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.DEVKEY)\n",
    "## uncomment once you have the test data\n",
    "gtnlplib.preproc.docsToBOWs(gtnlplib.constants.TESTKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of word types 113014\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.preproc)\n",
    "ac_train = gtnlplib.preproc.getAllCounts(gtnlplib.preproc.dataIterator(gtnlplib.constants.TRAINKEY))\n",
    "ac_dev = gtnlplib.preproc.getAllCounts(gtnlplib.preproc.dataIterator(gtnlplib.constants.DEVKEY))\n",
    "print \"number of word types\",len(ac_train.keys())-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Word list classification #\n",
    "(_setting weights - 2 pts, Deliverable 3 - 1 pt. Total 3 pts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poswords, negwords = gtnlplib.wordlist.loadSentimentWords (gtnlplib.constants.SENTIMENT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 classes in key: set(['NEG', 'NEU', 'POS'])\n",
      "3 classes in response: set(['NEG', 'NEU', 'POS'])\n",
      "confusion matrix\n",
      "key\\response:\tNEG\tNEU\tPOS\n",
      "NEG\t\t36\t14\t61\t\n",
      "NEU\t\t22\t14\t99\t\n",
      "POS\t\t9\t13\t126\t\n",
      "----------------\n",
      "accuracy: 0.4467 = 176/394\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.wordlist)\n",
    "weights_wlc = gtnlplib.wordlist.learnWLCWeights (poswords, negwords)\n",
    "outfile = 'word_list.txt'\n",
    "mat = gtnlplib.clf_base.evalClassifier(weights_wlc,outfile, gtnlplib.constants.DEVKEY)\n",
    "print gtnlplib.scorer.printScoreMessage(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Naive Bayes #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts, class_counts,allkeys = gtnlplib.preproc.getCountsAndKeys(gtnlplib.constants.TRAINKEY)\n",
    "reload(gtnlplib.naivebayes)\n",
    "weights_nb = gtnlplib.naivebayes.learnNBWeights (counts, class_counts, allkeys, alpha=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 classes in key: set(['NEG', 'NEU', 'POS'])\n",
      "3 classes in response: set(['NEG', 'NEU', 'POS'])\n",
      "confusion matrix\n",
      "key\\response:\tNEG\tNEU\tPOS\n",
      "NEG\t\t15\t85\t11\t\n",
      "NEU\t\t12\t97\t26\t\n",
      "POS\t\t8\t46\t94\t\n",
      "----------------\n",
      "accuracy: 0.5228 = 206/394\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "outfile = 'nb.txt'\n",
    "mat = gtnlplib.clf_base.evalClassifier(weights_nb,outfile, gtnlplib.constants.DEVKEY)\n",
    "print gtnlplib.scorer.printScoreMessage(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 1.3, 1.5, 1.8, 2, 5, 10] #your choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_nb_alphas, tr_accs, dv_accs = gtnlplib.naivebayes.regularization_using_grid_search (alphas,counts, class_counts, allkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 0.987820512821 0.467005076142\n",
      "0.001 0.986538461538 0.472081218274\n",
      "0.01 0.985897435897 0.507614213198\n",
      "0.1 0.982692307692 0.517766497462\n",
      "0.5 0.962179487179 0.515228426396\n",
      "1 0.94358974359 0.522842639594\n",
      "1.3 0.93141025641 0.522842639594\n",
      "1.5 0.924358974359 0.522842639594\n",
      "1.8 0.904487179487 0.522842639594\n",
      "2 0.896153846154 0.520304568528\n",
      "5 0.712820512821 0.464467005076\n",
      "10 0.605128205128 0.444162436548\n"
     ]
    }
   ],
   "source": [
    "for i,alpha in enumerate (alphas):\n",
    "    print alpha, tr_accs[i], dv_accs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Perceptron #\n",
    "(_ 6 points total _)\n",
    "\n",
    "Implement a perceptron classifier. Using the feature-function\n",
    "representation, include features for each word-class pair, and also an\n",
    "** offset ** feature for each class. Given a set of word counts $\\vec{x}_i$,\n",
    "a true label $y_i$, and a guessed label $\\hat{y}$, your update will be\n",
    "\\begin{align*}\n",
    "\\hat{y} & \\leftarrow \\text{argmax}_y \\vec{\\theta}' f(\\vec{x}_i,y)\\\\\n",
    "\\vec{\\theta} & \\leftarrow \\vec{\\theta} + f(\\vec{x}_i, y_i) - f(\\vec{x}_i, \\hat{y}).\n",
    "\\end{align*}\n",
    "\n",
    "Please write this yourself -- do not use any libraries, and try not to look\n",
    "at other code online.\n",
    "\n",
    "**Sanity check** If you are not careful, learning can be slow. \n",
    "You may need to think a little about how to do this update efficiently. \n",
    "\n",
    "- On my laptop, I can make 10 passes on the training data in roughly 30 seconds, including evaluating the accuracy on the dev and training sets. \n",
    "- You can use the ```%%timeit``` cell magic to compute statistics like this.\n",
    "- Your code doesn't have to be as fast as mine, but it needs to be written intelligently, and it needs to be fast enough for you to debug it properly.\n",
    "- The ```%%prun``` cell magic is also useful for diagnosing speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_tr_insts,all_dev_insts= gtnlplib.preproc.loadInstances(gtnlplib.constants.TRAINKEY, gtnlplib.constants.DEVKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev:  0.428934010152 train:  0.400641025641\n",
      "1 dev:  0.418781725888 train:  0.533974358974\n",
      "2 dev:  0.5 train:  0.616666666667\n",
      "3 dev:  0.403553299492 train:  0.662179487179\n",
      "4 dev:  0.505076142132 train:  0.657692307692\n",
      "5 dev:  0.560913705584 train:  0.755128205128\n",
      "6 dev:  0.527918781726 train:  0.798076923077\n",
      "7 dev:  0.477157360406 train:  0.839102564103\n",
      "8 dev:  0.46192893401 train:  0.790384615385\n",
      "9 dev:  0.52538071066 train:  0.836538461538\n",
      "10 dev:  0.535532994924 train:  0.882692307692\n",
      "11 dev:  0.530456852792 train:  0.898717948718\n",
      "12 dev:  0.52538071066 train:  0.917307692308\n",
      "13 dev:  0.555837563452 train:  0.90641025641\n",
      "14 dev:  0.545685279188 train:  0.933333333333\n",
      "15 dev:  0.520304568528 train:  0.955769230769\n",
      "16 dev:  0.540609137056 train:  0.967948717949\n",
      "17 dev:  0.560913705584 train:  0.967307692308\n",
      "18 dev:  0.530456852792 train:  0.958974358974\n",
      "19 dev:  0.482233502538 train:  0.95641025641\n",
      "20 dev:  0.472081218274 train:  0.971794871795\n",
      "21 dev:  0.530456852792 train:  0.971794871795\n",
      "22 dev:  0.53807106599 train:  0.98141025641\n",
      "23 dev:  0.53807106599 train:  0.970512820513\n",
      "24 dev:  0.530456852792 train:  0.980769230769\n",
      "25 dev:  0.56345177665 train:  0.95\n",
      "26 dev:  0.565989847716 train:  0.944871794872\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.perceptron)\n",
    "outfile = \"perc.txt\"\n",
    "w_perc,tr_acc_perc,dv_acc_perc = gtnlplib.perceptron.trainPerceptron(27, all_tr_insts,gtnlplib.constants.ALL_LABELS, outfile, gtnlplib.constants.DEVKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Averaged Perceptron #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev:  0.484771573604 train:  0.400641025641\n",
      "1 dev:  0.517766497462 train:  0.533974358974\n",
      "2 dev:  0.530456852792 train:  0.616666666667\n",
      "3 dev:  0.55076142132 train:  0.662179487179\n",
      "4 dev:  0.532994923858 train:  0.657692307692\n",
      "5 dev:  0.555837563452 train:  0.755128205128\n",
      "6 dev:  0.568527918782 train:  0.798076923077\n",
      "7 dev:  0.578680203046 train:  0.839102564103\n",
      "8 dev:  0.573604060914 train:  0.790384615385\n",
      "9 dev:  0.573604060914 train:  0.836538461538\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.avg_perceptron)\n",
    "# again, this takes roughly 30 seconds for me\n",
    "outfile = \"ap.txt\"\n",
    "w_ap,tr_acc_ap,dv_acc_ap = gtnlplib.avg_perceptron.trainAvgPerceptron(10,all_tr_insts,gtnlplib.constants.ALL_LABELS, outfile,gtnlplib.constants.DEVKEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Logistic regression #\n",
    "\n",
    "Now you will complete an implementation of logistic regression.\n",
    "We've provided a lot of scaffolding code, you just need to fill in some key parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev: 0.492385786802 train: 0.424631173829\n",
      "1 dev: 0.502538071066 train: 0.559332905709\n",
      "2 dev: 0.505076142132 train: 0.594611930725\n",
      "3 dev: 0.507614213198 train: 0.60936497755\n",
      "4 dev: 0.507614213198 train: 0.62604233483\n",
      "5 dev: 0.51269035533 train: 0.629249518922\n",
      "6 dev: 0.51269035533 train: 0.64271969211\n",
      "7 dev: 0.517766497462 train: 0.658114175754\n",
      "8 dev: 0.517766497462 train: 0.669660038486\n",
      "9 dev: 0.517766497462 train: 0.679923027582\n",
      "10 dev: 0.515228426396 train: 0.689544579859\n",
      "11 dev: 0.51269035533 train: 0.698524695318\n",
      "12 dev: 0.51269035533 train: 0.712636305324\n",
      "13 dev: 0.520304568528 train: 0.71840923669\n",
      "14 dev: 0.522842639594 train: 0.730596536241\n",
      "15 dev: 0.522842639594 train: 0.737652341244\n",
      "16 dev: 0.522842639594 train: 0.744708146248\n",
      "17 dev: 0.52538071066 train: 0.753688261706\n",
      "18 dev: 0.522842639594 train: 0.754329698525\n",
      "19 dev: 0.522842639594 train: 0.762668377165\n",
      "20 dev: 0.52538071066 train: 0.76908274535\n",
      "21 dev: 0.52538071066 train: 0.773572803079\n",
      "22 dev: 0.530456852792 train: 0.778704297627\n",
      "23 dev: 0.527918781726 train: 0.782552918538\n",
      "24 dev: 0.527918781726 train: 0.783194355356\n",
      "25 dev: 0.530456852792 train: 0.787042976267\n",
      "26 dev: 0.527918781726 train: 0.792815907633\n",
      "27 dev: 0.527918781726 train: 0.795381654907\n",
      "28 dev: 0.530456852792 train: 0.797305965362\n",
      "29 dev: 0.530456852792 train: 0.801796023092\n",
      "30 dev: 0.532994923858 train: 0.803720333547\n",
      "31 dev: 0.532994923858 train: 0.808851828095\n",
      "32 dev: 0.532994923858 train: 0.815907633098\n",
      "33 dev: 0.530456852792 train: 0.819756254009\n",
      "34 dev: 0.532994923858 train: 0.820397690827\n",
      "35 dev: 0.532994923858 train: 0.824246311738\n",
      "36 dev: 0.532994923858 train: 0.824246311738\n",
      "37 dev: 0.532994923858 train: 0.825529185375\n",
      "38 dev: 0.532994923858 train: 0.828094932649\n",
      "39 dev: 0.532994923858 train: 0.830660679923\n",
      "40 dev: 0.532994923858 train: 0.83194355356\n",
      "41 dev: 0.527918781726 train: 0.834509300834\n",
      "42 dev: 0.527918781726 train: 0.833867864015\n",
      "43 dev: 0.527918781726 train: 0.835792174471\n",
      "44 dev: 0.527918781726 train: 0.836433611289\n",
      "45 dev: 0.532994923858 train: 0.839640795382\n",
      "46 dev: 0.532994923858 train: 0.842206542656\n",
      "47 dev: 0.532994923858 train: 0.844772289929\n",
      "48 dev: 0.532994923858 train: 0.846055163566\n",
      "49 dev: 0.532994923858 train: 0.847979474022\n",
      "50 dev: 0.532994923858 train: 0.847979474022\n",
      "51 dev: 0.532994923858 train: 0.84862091084\n",
      "52 dev: 0.530456852792 train: 0.850545221296\n",
      "53 dev: 0.530456852792 train: 0.853752405388\n",
      "54 dev: 0.530456852792 train: 0.854393842207\n",
      "55 dev: 0.532994923858 train: 0.855035279025\n",
      "56 dev: 0.532994923858 train: 0.857601026299\n",
      "57 dev: 0.532994923858 train: 0.858242463117\n",
      "58 dev: 0.532994923858 train: 0.860166773573\n",
      "59 dev: 0.532994923858 train: 0.860808210391\n",
      "60 dev: 0.532994923858 train: 0.862732520847\n",
      "61 dev: 0.532994923858 train: 0.862732520847\n",
      "62 dev: 0.532994923858 train: 0.865298268121\n",
      "63 dev: 0.532994923858 train: 0.865939704939\n",
      "64 dev: 0.53807106599 train: 0.865939704939\n",
      "65 dev: 0.540609137056 train: 0.867222578576\n",
      "66 dev: 0.540609137056 train: 0.869146889031\n",
      "67 dev: 0.540609137056 train: 0.870429762668\n",
      "68 dev: 0.540609137056 train: 0.872354073124\n",
      "69 dev: 0.540609137056 train: 0.873636946761\n",
      "70 dev: 0.543147208122 train: 0.874278383579\n",
      "71 dev: 0.543147208122 train: 0.874919820398\n",
      "72 dev: 0.543147208122 train: 0.876844130853\n",
      "73 dev: 0.543147208122 train: 0.877485567672\n",
      "74 dev: 0.543147208122 train: 0.87812700449\n",
      "75 dev: 0.543147208122 train: 0.880692751764\n",
      "76 dev: 0.543147208122 train: 0.881334188582\n",
      "77 dev: 0.543147208122 train: 0.881975625401\n",
      "78 dev: 0.543147208122 train: 0.883258499038\n",
      "79 dev: 0.543147208122 train: 0.885182809493\n",
      "80 dev: 0.543147208122 train: 0.885182809493\n",
      "81 dev: 0.545685279188 train: 0.885824246312\n",
      "82 dev: 0.545685279188 train: 0.88646568313\n",
      "83 dev: 0.543147208122 train: 0.88646568313\n",
      "84 dev: 0.543147208122 train: 0.88646568313\n",
      "85 dev: 0.543147208122 train: 0.887107119949\n",
      "86 dev: 0.545685279188 train: 0.888389993586\n",
      "87 dev: 0.545685279188 train: 0.889031430404\n",
      "88 dev: 0.548223350254 train: 0.889031430404\n",
      "89 dev: 0.548223350254 train: 0.889031430404\n",
      "90 dev: 0.548223350254 train: 0.889031430404\n",
      "91 dev: 0.548223350254 train: 0.889031430404\n",
      "92 dev: 0.55076142132 train: 0.890314304041\n",
      "93 dev: 0.55076142132 train: 0.890314304041\n",
      "94 dev: 0.55076142132 train: 0.89095574086\n",
      "95 dev: 0.55076142132 train: 0.89095574086\n",
      "96 dev: 0.553299492386 train: 0.89095574086\n",
      "97 dev: 0.555837563452 train: 0.891597177678\n",
      "98 dev: 0.555837563452 train: 0.891597177678\n",
      "99 dev: 0.555837563452 train: 0.892238614496\n",
      "100 dev: 0.555837563452 train: 0.892880051315\n",
      "101 dev: 0.555837563452 train: 0.892880051315\n",
      "102 dev: 0.555837563452 train: 0.893521488133\n",
      "103 dev: 0.555837563452 train: 0.895445798589\n",
      "104 dev: 0.555837563452 train: 0.895445798589\n",
      "105 dev: 0.555837563452 train: 0.895445798589\n",
      "106 dev: 0.555837563452 train: 0.895445798589\n",
      "107 dev: 0.555837563452 train: 0.895445798589\n",
      "108 dev: 0.553299492386 train: 0.895445798589\n",
      "109 dev: 0.553299492386 train: 0.895445798589\n",
      "110 dev: 0.553299492386 train: 0.895445798589\n",
      "111 dev: 0.553299492386 train: 0.895445798589\n",
      "112 dev: 0.553299492386 train: 0.895445798589\n",
      "113 dev: 0.553299492386 train: 0.895445798589\n",
      "114 dev: 0.553299492386 train: 0.896087235407\n",
      "115 dev: 0.553299492386 train: 0.896087235407\n",
      "116 dev: 0.553299492386 train: 0.896087235407\n",
      "117 dev: 0.553299492386 train: 0.896728672226\n",
      "118 dev: 0.553299492386 train: 0.896728672226\n",
      "119 dev: 0.555837563452 train: 0.896728672226\n",
      "120 dev: 0.555837563452 train: 0.897370109044\n",
      "121 dev: 0.555837563452 train: 0.898011545863\n",
      "122 dev: 0.555837563452 train: 0.898011545863\n",
      "123 dev: 0.555837563452 train: 0.898011545863\n",
      "124 dev: 0.555837563452 train: 0.898652982681\n",
      "125 dev: 0.555837563452 train: 0.898652982681\n",
      "126 dev: 0.555837563452 train: 0.8992944195\n",
      "127 dev: 0.555837563452 train: 0.8992944195\n",
      "128 dev: 0.555837563452 train: 0.8992944195\n",
      "129 dev: 0.555837563452 train: 0.8992944195\n",
      "130 dev: 0.555837563452 train: 0.899935856318\n",
      "131 dev: 0.555837563452 train: 0.901218729955\n",
      "132 dev: 0.555837563452 train: 0.901218729955\n",
      "133 dev: 0.555837563452 train: 0.901860166774\n",
      "134 dev: 0.555837563452 train: 0.901860166774\n",
      "135 dev: 0.555837563452 train: 0.903784477229\n",
      "136 dev: 0.555837563452 train: 0.904425914047\n",
      "137 dev: 0.555837563452 train: 0.905067350866\n",
      "138 dev: 0.555837563452 train: 0.906350224503\n",
      "139 dev: 0.555837563452 train: 0.906350224503\n",
      "140 dev: 0.555837563452 train: 0.906350224503\n",
      "141 dev: 0.555837563452 train: 0.906350224503\n",
      "142 dev: 0.555837563452 train: 0.906350224503\n",
      "143 dev: 0.555837563452 train: 0.90763309814\n",
      "144 dev: 0.555837563452 train: 0.90763309814\n",
      "145 dev: 0.555837563452 train: 0.90763309814\n",
      "146 dev: 0.555837563452 train: 0.90763309814\n",
      "147 dev: 0.553299492386 train: 0.90763309814\n",
      "148 dev: 0.553299492386 train: 0.90763309814\n",
      "149 dev: 0.553299492386 train: 0.90763309814\n",
      "150 dev: 0.553299492386 train: 0.90763309814\n",
      "151 dev: 0.553299492386 train: 0.908274534958\n",
      "152 dev: 0.553299492386 train: 0.908274534958\n",
      "153 dev: 0.553299492386 train: 0.909557408595\n",
      "154 dev: 0.553299492386 train: 0.910840282232\n",
      "155 dev: 0.553299492386 train: 0.910840282232\n",
      "156 dev: 0.553299492386 train: 0.910840282232\n",
      "157 dev: 0.553299492386 train: 0.910840282232\n",
      "158 dev: 0.553299492386 train: 0.911481719051\n",
      "159 dev: 0.555837563452 train: 0.912123155869\n",
      "160 dev: 0.555837563452 train: 0.912123155869\n",
      "161 dev: 0.555837563452 train: 0.912123155869\n",
      "162 dev: 0.555837563452 train: 0.912123155869\n",
      "163 dev: 0.555837563452 train: 0.912123155869\n",
      "164 dev: 0.555837563452 train: 0.912123155869\n",
      "165 dev: 0.555837563452 train: 0.912764592688\n",
      "166 dev: 0.555837563452 train: 0.912764592688\n",
      "167 dev: 0.555837563452 train: 0.912764592688\n",
      "168 dev: 0.555837563452 train: 0.912764592688\n",
      "169 dev: 0.555837563452 train: 0.912764592688\n",
      "170 dev: 0.555837563452 train: 0.912764592688\n",
      "171 dev: 0.555837563452 train: 0.912764592688\n",
      "172 dev: 0.555837563452 train: 0.912764592688\n",
      "173 dev: 0.555837563452 train: 0.912764592688\n",
      "174 dev: 0.555837563452 train: 0.912764592688\n",
      "175 dev: 0.555837563452 train: 0.912764592688\n",
      "176 dev: 0.558375634518 train: 0.912764592688\n",
      "177 dev: 0.558375634518 train: 0.912764592688\n",
      "178 dev: 0.558375634518 train: 0.912764592688\n",
      "179 dev: 0.558375634518 train: 0.912764592688\n",
      "180 dev: 0.558375634518 train: 0.912764592688\n",
      "181 dev: 0.558375634518 train: 0.912764592688\n",
      "182 dev: 0.558375634518 train: 0.913406029506\n",
      "183 dev: 0.558375634518 train: 0.913406029506\n",
      "184 dev: 0.558375634518 train: 0.913406029506\n",
      "185 dev: 0.558375634518 train: 0.914047466325\n",
      "186 dev: 0.558375634518 train: 0.914047466325\n",
      "187 dev: 0.558375634518 train: 0.914047466325\n",
      "188 dev: 0.558375634518 train: 0.914688903143\n",
      "189 dev: 0.558375634518 train: 0.914688903143\n",
      "190 dev: 0.558375634518 train: 0.914688903143\n",
      "191 dev: 0.558375634518 train: 0.914688903143\n",
      "192 dev: 0.558375634518 train: 0.914688903143\n",
      "193 dev: 0.558375634518 train: 0.914688903143\n",
      "194 dev: 0.558375634518 train: 0.914688903143\n",
      "195 dev: 0.558375634518 train: 0.914688903143\n",
      "196 dev: 0.558375634518 train: 0.914688903143\n",
      "197 dev: 0.558375634518 train: 0.914688903143\n",
      "198 dev: 0.558375634518 train: 0.915330339962\n",
      "199 dev: 0.558375634518 train: 0.915330339962\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.logreg)\n",
    "outfile = \"sgd.txt\"\n",
    "w_sgd,tr_acc_sgd,dv_acc_sgd = gtnlplib.logreg.trainLRbySGD(200,all_tr_insts, outfile, gtnlplib.constants.DEVKEY, regularizer=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Bakeoff! #\n",
    "\n",
    "48 hours before the assignment is due, I will send you unlabeled test\n",
    "data. Your job is to produce a response file, and submit it to our Kaggle\n",
    "bakeoff ([link here](https://inclass.kaggle.com/c/gt-book-review-sentiment-analysis)).\n",
    "The Kaggle contest compares your classifier's results on the dev data to generate a\n",
    "class-visible leaderboard, and compares your classifier's results on the unlabeled\n",
    "test data for the bakeoff. You can use the dev data results as a sanity\n",
    "check, to make sure you submit the correct file.\n",
    "\n",
    "I'll present the results in class and give the best scorers a chance to explain\n",
    "what they did.\n",
    "\n",
    "** Deliverable 10 ** (3 points) Run your best system from any part of the\n",
    "assignment on the test data using the `generateKaggleSubmission()` function. Submit\n",
    "your response file to the class [Kaggle bakeoff](https://inclass.kaggle.com/c/gt-book-review-sentiment-analysis). Also submit your Kaggle response file to T-Square as 'lastname-firstname.response'. The top\n",
    "scores will be announced in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634517766497 2.4 1.2 0.1 0.8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-d49c3241b4fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                 \u001b[0mavg_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgtnlplib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_ensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_wlc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mweights_nb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw_ap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mw_sgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0myourBestWeights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_weight\u001b[0m \u001b[1;31m# Change this to your best model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgtnlplib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerateKaggleSubmission\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myourBestWeights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dai-Hanjun.response'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                     \u001b[0mbest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hanjun/Workspace/Courses/gt-nlp-class/psets/better-ps2/gtnlplib/clf_base.pyc\u001b[0m in \u001b[0;36mgenerateKaggleSubmission\u001b[1;34m(weights, outfilename)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mtestData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTESTKEY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mpredictedLabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mALL_LABELS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0mpredictedIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mALL_LABELS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictedLabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             writer.writerow({\n",
      "\u001b[1;32m/home/hanjun/Workspace/Courses/gt-nlp-class/psets/better-ps2/gtnlplib/clf_base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(instance, weights, labels)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.weight_ensemble)\n",
    "reload(gtnlplib.clf_base)\n",
    "best_acc = 0.0\n",
    "for w4 in np.arange(0.8, 10, 0.1):\n",
    "    for w3 in np.arange(0.1, 10, 0.1):\n",
    "                w1 = 2.4\n",
    "                w2 = 1.2\n",
    "                avg_weight = gtnlplib.weight_ensemble.ensemble([(weights_wlc, w1), (weights_nb, w2), (w_ap, w3), (w_sgd, w4)])\n",
    "                yourBestWeights = avg_weight # Change this to your best model\n",
    "                acc = gtnlplib.clf_base.generateKaggleSubmission(yourBestWeights, 'Dai-Hanjun.response')\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_w1 = w1\n",
    "                    best_w2 = w2\n",
    "                    best_w3 = w3\n",
    "                    best_w4 = w4\n",
    "                    print best_acc, w1, w2, w3, w4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
